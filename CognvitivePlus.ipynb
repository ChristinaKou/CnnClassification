{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CognvitivePlus",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTYTbcZY6adWIOlwaxQYi5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristinaKou/Congitive-/blob/Classifier/CognvitivePlus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Gbwy7mpE1W",
        "colab_type": "text"
      },
      "source": [
        "# **Christina Koutsoumpa** -  Classification of small images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtEXc68KrYsU",
        "colab_type": "text"
      },
      "source": [
        "# **1. Initialisation and function definitions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf-ocpwAhsE5",
        "colab_type": "text"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFA6b9U7iOrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt \n",
        "import tarfile\n",
        "from random import randrange\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLi3jxo8pzU1",
        "colab_type": "text"
      },
      "source": [
        "Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mpvqWAghIrQl",
        "colab": {}
      },
      "source": [
        "# Project directory\n",
        "workingDir = '/Cognitive'\n",
        "# Make a project folder if not existent\n",
        "if not os.path.exists(workingDir):\n",
        "    os.makedirs(workingDir)\n",
        "os.chdir(workingDir) # Cd to this foder \n",
        "print(\"The current workig directory is\",os.getcwd()[1:] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPDOYlnMrs0c",
        "colab_type": "text"
      },
      "source": [
        "Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-k2OSBDjHP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List non hidden files in current folder\n",
        "def nonHiddenfiles():\n",
        "  fileList = [n_file for n_file in os.listdir() if not n_file.startswith('.')] \n",
        "  return fileList\n",
        "\n",
        "# Unpickle file\n",
        "def unpickle(file):\n",
        "  import pickle\n",
        "  with open(file, 'rb') as fo:\n",
        "    dict = pickle.load(fo, encoding='bytes')\n",
        "  return dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "747HpAqlgCuX",
        "colab_type": "text"
      },
      "source": [
        "# **2. Data Loading and preprocessing**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hznt2MB-f0ag",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Download and decompress dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9rQQR8jf_ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset if not already downloaded\n",
        "fileList = nonHiddenfiles()\n",
        "if len(fileList)==0: # Check for non hidden files\n",
        "  # Donwload \n",
        "  print(\"Downloading data ..\")\n",
        "  !wget -q --show-progress https://www.cs.toronto.edu/%7Ekriz/cifar-100-python.tar.gz\n",
        "  fileList = nonHiddenfiles()\n",
        "  print(\"Dataset\", fileList[-1],  \"downloaded\" )\n",
        "else:\n",
        "  # Do not download\n",
        "  print(\"Dataset\", fileList[-1], \"already downloaded\" )\n",
        "  fileList = nonHiddenfiles()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1w3VR6wlt_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decompress dataset\n",
        "fileList = nonHiddenfiles()\n",
        "datasetFile = fileList[-1]\n",
        "if datasetFile.endswith(\"tar.gz\"):\n",
        "  print(\"Decompressing dataset..\")    \n",
        "  tar = tarfile.open(datasetFile, \"r:gz\")    \n",
        "  tar.extractall()\n",
        "  tar.close()\n",
        "  print(\"..into\", tar.name)\n",
        "  os.remove(tar.name) # delete compressed file\n",
        "  fileList.remove(datasetFile)\n",
        "else:\n",
        "  print(\"Dataset uncompressed\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm9BUdfvudW0",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Explore dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqkU35pDy83V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look into the folder\n",
        "os.chdir(tar.members[0].name) \n",
        "# List non hidden content\n",
        "contentList = nonHiddenfiles()\n",
        "print(*contentList, sep = \"\\n\")\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxz2plQxzpkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unpickle data \n",
        "os.chdir(tar.members[0].name)\n",
        "test = unpickle(contentList[0])\n",
        "meta = unpickle(contentList[1])\n",
        "train = unpickle(contentList[3])\n",
        "print(type(test), type(meta), type(train))\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhE3TZR4OjDc",
        "colab_type": "text"
      },
      "source": [
        "### Table of dataset summary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3J_gO9q5mb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\tLABEL\",\"\\t\\t\\t\",\"LENGTH\\t\\t\", \"VALUE\")\n",
        "\n",
        "# expore meta dataset\n",
        "print(\"META\")\n",
        "for i in list(range(0,len(meta))):\n",
        "  print(list(meta.keys())[i],\"\\t\\t\",len(list(test.values())[i]),\"\\t\\t\",list(meta.values())[i]), print('\\n')\n",
        "\n",
        "# expore train dataset\n",
        "print(\"TRAIN\")\n",
        "for i in list(range(0,len(train))):\n",
        "  print(list(train.keys())[i],\"      \\t\\t\",len(list(train.values())[i]),\"\\t\\t\",list(train.values())[i]), print('\\n')\n",
        "\n",
        "# expore test dataset\n",
        "print(\"TEST\")\n",
        "for i in list(range(0,len(test))):\n",
        "  print(list(test.keys())[i],\":          \\t\",len(list(test.values())[i]),\"\\t\\t\", list(test.values())[i]), print('\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd8bvsPzOFZS",
        "colab_type": "text"
      },
      "source": [
        "### Image examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSSt_1wBFQ1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type and shape of image data\n",
        "print(type(train[b'data']),train[b'data'].shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi2y69cWVifJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape dataset\n",
        "trainImages = train[b'data'].reshape(50000,3,32,32).transpose(2,3,1,0);\n",
        "trainImages.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtCT5akMQ6fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show random image examples with their filename, coarse category and fine category\n",
        "%matplotlib inline\n",
        "thisImage=randrange(len(train[b'filenames']));\n",
        "plt.imshow(trainImages[:,:,:,thisImage].squeeze());\n",
        "plt.title([train[b'filenames'][thisImage], meta[b'fine_label_names'][train[b'fine_labels'][thisImage]],meta[b'coarse_label_names'][train[b'coarse_labels'][thisImage]]] );\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4LgclFStgZa",
        "colab_type": "text"
      },
      "source": [
        "# **3. Classifier training**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjujY_a6uZ3O",
        "colab_type": "text"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVGNlIZguSsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bMTu3__hZsE",
        "colab_type": "text"
      },
      "source": [
        "Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox-kPbwNhYxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQxQ9-e2Zf09",
        "colab_type": "text"
      },
      "source": [
        "# 3.1. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtaRyp1Ja0H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "# First convolutional layer \n",
        "classifier.add(Convolution2D(32, (3, 3), input_shape = (32, 32, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Second convolutional layer \n",
        "classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Full connection\n",
        "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
        "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Print topology\n",
        "classifier.summary(80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np3Zc8zTZzv4",
        "colab_type": "text"
      },
      "source": [
        "* Layers: 2 convolutional and max-pooling layers, 1 flatten layer, 2 fully connected layers with ReLU and sigmoid\n",
        "* Activation function : ReLU\n",
        "* Loss function : cross entropy\n",
        "* Optimiser: Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls30Vo9HfwEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "from keras.utils import plot_model\n",
        "plot_model(classifier, to_file='model.png')\n",
        "\n",
        "#from IPython.display import Image \n",
        "#Image('model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ofETh83g9-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb8C94fGd5hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   rotation_range=15,\n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='reflect',\n",
        "                                   data_format='channels_last',\n",
        "                                   brightness_range=[0.5, 1.5],\n",
        "                                   featurewise_center=True,\n",
        "                                   featurewise_std_normalization=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYkkj_T9d9vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('dataset/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('dataset/validation',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj6r4X7nZK8R",
        "colab_type": "text"
      },
      "source": [
        "Activation function ReLU, leaky ReLU, Swish\n",
        "\n",
        "Multi-Class Cross-Entropy Loss, Sparse Multiclass Cross-Entropy Loss, Kullback Leibler Divergence Loss\n",
        "\n",
        "adam, sgd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktQinrikuob5",
        "colab_type": "text"
      },
      "source": [
        "# Citations\n",
        "1. https://www.cs.toronto.edu/~kriz/cifar.html (dataset)\n",
        "2. https://www.tensorflow.org/tensorboard/graphs "
      ]
    }
  ]
}